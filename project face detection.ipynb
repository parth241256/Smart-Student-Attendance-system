{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.22.1.tar.gz (7.4 MB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.22.1-cp38-cp38-win_amd64.whl size=2949038 sha256=2e1f4bafb6c9e75f3176efe94f8230ff6bc6c219cee13dfd1bcf4737c88a240f\n",
      "  Stored in directory: c:\\users\\pp987\\appdata\\local\\pip\\cache\\wheels\\c3\\7d\\3d\\896cb44b682ef7c2c080d7d5d312ce8ba253aa4b03f858d398\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.22.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in c:\\users\\pp987\\anaconda3\\lib\\site-packages (3.21.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face-recognition\n",
      "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\pp987\\anaconda3\\lib\\site-packages (from face-recognition) (7.1.2)\n",
      "Collecting face-recognition-models>=0.3.0\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\pp987\\anaconda3\\lib\\site-packages (from face-recognition) (19.22.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pp987\\anaconda3\\lib\\site-packages (from face-recognition) (1.19.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pp987\\anaconda3\\lib\\site-packages (from face-recognition) (8.0.1)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py): started\n",
      "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566176 sha256=4c15f528b99ffe654e28327d4e6716567a8d92bac983ec124c513158110155b3\n",
      "  Stored in directory: c:\\users\\pp987\\appdata\\local\\pip\\cache\\wheels\\b4\\4b\\8f\\751e99d45f089bdf366a7d3e5066db3c2b84a62e4377f534d7\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models, face-recognition\n",
      "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pp987\\\\Desktop\\\\Internship 2021'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgparth = face_recognition.load_image_file('photos/parth.jpg')\n",
    "imgparth = cv2.cvtColor(imgparth,cv2.COLOR_BGR2RGB)\n",
    "imgTest = face_recognition.load_image_file('photos/parth_test.jpg')\n",
    "imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('parth patel',imgparth)\n",
    "cv2.imshow('parth test',imgTest)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[180, 192, 204],\n",
       "        [180, 192, 204],\n",
       "        [180, 192, 204],\n",
       "        ...,\n",
       "        [168, 186, 193],\n",
       "        [168, 185, 194],\n",
       "        [169, 184, 193]],\n",
       "\n",
       "       [[179, 191, 203],\n",
       "        [180, 192, 204],\n",
       "        [180, 192, 204],\n",
       "        ...,\n",
       "        [167, 185, 192],\n",
       "        [169, 184, 193],\n",
       "        [168, 183, 192]],\n",
       "\n",
       "       [[179, 191, 203],\n",
       "        [180, 192, 204],\n",
       "        [180, 192, 204],\n",
       "        ...,\n",
       "        [167, 185, 192],\n",
       "        [167, 184, 193],\n",
       "        [168, 183, 192]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[151, 156, 135],\n",
       "        [156, 161, 140],\n",
       "        [156, 161, 140],\n",
       "        ...,\n",
       "        [162, 162, 146],\n",
       "        [160, 160, 144],\n",
       "        [161, 161, 145]],\n",
       "\n",
       "       [[153, 158, 137],\n",
       "        [153, 158, 137],\n",
       "        [148, 153, 132],\n",
       "        ...,\n",
       "        [161, 161, 145],\n",
       "        [159, 159, 143],\n",
       "        [159, 159, 143]],\n",
       "\n",
       "       [[155, 160, 139],\n",
       "        [151, 156, 135],\n",
       "        [149, 154, 133],\n",
       "        ...,\n",
       "        [159, 159, 143],\n",
       "        [160, 160, 144],\n",
       "        [158, 158, 142]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceLoc = face_recognition.face_locations(imgparth)[0]\n",
    "encodeparth = face_recognition.face_encodings(imgparth)[0]\n",
    "cv2.rectangle(imgparth,(faceLoc[3],faceLoc[0]),(faceLoc[1],faceLoc[2]),(255,0,255),2) # top, right, bottom, left\n",
    "\n",
    "faceLocTest = face_recognition.face_locations(imgTest)[0]\n",
    "encodeTest = face_recognition.face_encodings(imgTest)[0]\n",
    "cv2.rectangle(imgTest,(faceLoc[3],faceLoc[0]),(faceLoc[1],faceLoc[2]),(255,0,255),2) # top, right, bottom, left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes Detected: 4\n",
      "['alex.jpg', 'parth.jpg', 'parth_test.jpg', 'sameeda.jpg']\n"
     ]
    }
   ],
   "source": [
    "path = 'photos'\n",
    "images = []     # LIST CONTAINING ALL THE IMAGES\n",
    "className = []    # LIST CONTAINING ALL THE CORRESPONDING CLASS Names\n",
    "myList = os.listdir(path)\n",
    "print(\"Total Classes Detected:\",len(myList))\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alex', 'parth', 'parth_test', 'sameeda']\n"
     ]
    }
   ],
   "source": [
    "for cl in myList:\n",
    "        curImg = cv2.imread(f'{path}/{cl}')\n",
    "        images.append(curImg)\n",
    "        className.append(os.path.splitext(cl)[0])\n",
    "print(className)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodings Complete\n"
     ]
    }
   ],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encodings Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH_TEST\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH_TEST\n",
      "PARTH_TEST\n",
      "PARTH_TEST\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n",
      "PARTH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0, 0),None,0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "        \n",
    "        if matches[matchIndex]:\n",
    "            name = className[matchIndex].upper()\n",
    "            print(name)\n",
    "            y1,x2,y2,x1=faceLoc\n",
    "            y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\pp987\\Desktop\\Internship 2021\\photos\\IMG_1123'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-685e4e189ce6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Load the image into an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/pp987/Desktop/Internship 2021/photos/IMG_1123\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Run the HOG face detector on the image data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m                                (plugin, kind))\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\pp987\\Desktop\\Internship 2021\\photos\\IMG_1123'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import dlib\n",
    "from skimage import io\n",
    "\n",
    "# Take the image file name from the command line\n",
    "file_name = \"C:/Users/pp987/Desktop/Internship 2021/photos/IMG_1123\"\n",
    "\n",
    "# Create a HOG face detector using the built-in dlib class\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "win = dlib.image_window()\n",
    "\n",
    "# Load the image into an array\n",
    "image = io.imread(\"C:/Users/pp987/Desktop/Internship 2021/photos/IMG_1123\")\n",
    "\n",
    "# Run the HOG face detector on the image data.\n",
    "# The result will be the bounding boxes of the faces in our image.\n",
    "detected_faces = face_detector(image, 1)\n",
    "\n",
    "print(\"I found {} faces in the file {}\".format(len(detected_faces), file_name))\n",
    "\n",
    "# Open a window on the desktop showing the image\n",
    "win.set_image(image)\n",
    "\n",
    "# Loop through each face we found in the image\n",
    "for i, face_rect in enumerate(detected_faces):\n",
    "\n",
    "\t# Detected faces are returned as an object with the coordinates \n",
    "\t# of the top, left, right and bottom edges\n",
    "\tprint(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n",
    "\n",
    "\t# Draw a box around each face we found\n",
    "\twin.add_overlay(face_rect)\n",
    "\t        \n",
    "# Wait until the user hits <enter> to close the window\t        \n",
    "dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow('img', img)\n",
    "\n",
    "    # Stop if escape key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "# Release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
